{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NonokaShimada/Class_report_3/blob/main/Class_report_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('group 11',\n",
        "      'name: Nonoka Shimada, Moe Umezaki, Millymarion Tani')"
      ],
      "metadata": {
        "id": "oDBS35ALmD2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRFqCzVoBZp-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b057c488-4267-4d0d-e90c-4644c50fcede"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.4054311213854046\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import kendalltau \n",
        "import pandas as pd\n",
        "\n",
        "X1 = [5712.000, 6.600, 44.500, 5.700, 4603.000, 179.500, 0.300, 169.000, \n",
        "     25.600, 440.000, 6.400, 423.000, 2.400, 419.000, 1.200, 25.000, \n",
        "     3.500, 5.000, 17.500, 81.000, 680.000, 115.000, 1.000, 406.000,  \n",
        "     325.000, 119.500, 4.000, 5.500, 655.000, 157.000, 56.000, 0.140,\n",
        "     0.250, 1320.000, 3.000, 8.100, 0.400, 0.330, 6.300, 10.800, 490.000,\n",
        "     15.500, 115.000, 11.400, 180.000, 12.100, 39.200,\n",
        "     1.900, 50.400, 179.000, 12.300, 21.000, 98.200, 175.000, 12.500, \n",
        "     1.000, 2.600, 12.300, 2.500, 58.000, 3.900, 17.000]\n",
        "Y1 =  [3.3, 8.3, 12.5, 16.5, 3.9, 9.8, 19.7, 6.2, 14.5, 9.7, 12.5, \n",
        "      3.9, 10.3, 3.1, 8.4, 8.6, 10.7, 10.7, 6.1, 18.1, 0.0, 3.8, 14.4,\n",
        "      12.0, 6.2, 13.0, 13.8, 8.2, 2.9, 10.8, 0.0, 9.1, 19.9, 8.0, 10.6, \n",
        "      11.2, 13.2, 12.8, 19.4, 17.4, 0.0, 17.0, 10.9, 13.7, 8.4, 8.4, \n",
        "      12.5, 13.2, 9.8, 9.6, 6.6, 5.4, 2.6, 3.8, 11.0, 10.3, 13.3, \n",
        "      5.4, 15.8, 10.3, 19.4, 3.0]\n",
        "\n",
        "print('execise 3.1')\n",
        "corr, _ = kendalltau(X1, Y1)\n",
        "print( corr)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import index\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import csv \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "f1 = pd.read_csv('https://raw.githubusercontent.com/NonokaShimada/Class_report_3/main/sea_level_means.csv')\n",
        "\n",
        "f1_df = pd.DataFrame(data=f1)\n",
        "x2 = ('1983', '1984', '1985', '1986', '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995', '1996',\n",
        "       '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010',\n",
        "       '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021' )\n",
        "y2 = (0.205534, 0.243309, 0.215098, 0.227934, 0.250639, 0.223315, 0.169404, 0.165727, 0.189217, 0.179606, 0.189362, \n",
        "     0.217203, 0.222095, 0.278264, 0.251553, 0.250564, 0.256932, 0.255659, 0.291578, 0.289169, 0.240188, 0.276130, \n",
        "     0.258384, 0.263417, 0.256723, 0.279518, 0.333497, 0.403689, 0.292861, 0.294969, 0.363099, 0.394371, 0.312640,\n",
        "     0.324298, 0.284031, 0.353556, 0.350941, 0.318164, 0.328623)\n",
        "plt.scatter(x=x2, y=y2, c='blue')\n",
        "sns.set(rc={'figure.figsize':(20,8)})\n",
        "\n",
        "print('3.2_a')\n",
        "print(f1_df)\n"
      ],
      "metadata": {
        "id": "o477d2UY-JuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f2 = pd.read_csv('https://raw.githubusercontent.com/NonokaShimada/Class_report_3/main/sea_level_daily_maxs.csv')\n",
        "df1 = f2.describe().loc[['mean','max']]\n",
        "\n",
        "df2 =pd.concat([f1_df, df1])\n",
        "df2.index = ['avg level', 'mean', 'max']\n",
        "\n",
        "print('3.2_b')\n",
        "print(df2)\n",
        "\n",
        "plt.scatter(data=df2,\n",
        "                x=x2,\n",
        "                y=df2['avg level', 'mean','max'],\n",
        "                c='blue')\n"
      ],
      "metadata": {
        "id": "B-T0D6_Y3hgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = f2.max()\n",
        "df3_a = pd.DataFrame(data=df3)\n",
        "df3_a.columns = ['level']\n",
        "df3_b = df3_a.iloc[2:41]\n",
        "print('3.2_c')\n",
        "print(df3_b)\n",
        "sns.boxplot(data=df3_b,\n",
        "            y='level')\n",
        "sns.set(rc={'figure.figsize':(20,8)})"
      ],
      "metadata": {
        "id": "aQYb_akbUAE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('3.2_d')\n",
        "print('the sea level in 2021 is really low.',\n",
        "      'Although this is not the lowest, but much lower than average.')"
      ],
      "metadata": {
        "id": "3kqRCdmtiyPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_a-dfimport networkx as nx\n",
        "import pandas as pd \n",
        "import csv \n",
        "\n",
        "url_2 = 'https://raw.githubusercontent.com/NonokaShimada/Class_report_3/main/lastfm_asia_edges.csv'\n",
        "df2 = pd.read_csv(url_2)\n",
        "G = url_2\n",
        "nx.draw(G, with_labels=True)\n",
        "print ('Degree Centrality', nx.degree_centrality(G))\n",
        "print ('Eccen_tricity Centrality', nx.eccentricity_centrality(G))\n",
        "print('Harmonic Centrarity', nx.harmonic_centrality(G))\n",
        "print('Closeness Centrality', nx.closeness_centrality(G))\n",
        "print(df2)"
      ],
      "metadata": {
        "id": "2C9H6QoP8e4G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}